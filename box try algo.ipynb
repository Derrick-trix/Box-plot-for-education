{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import sparse\n",
    "from sklearn import preprocessing, linear_model\n",
    "import sklearn.feature_extraction.text as txt\n",
    "\n",
    "def clean(s):\n",
    "    try:\n",
    "        return \" \".join(re.findall(r'\\w+', s)).lower()\n",
    "    except:\n",
    "        \n",
    "        return \" \".join(re.findall(r'\\w+', \"no_text\")).lower()\n",
    "\n",
    "train = pd.read_csv('TrainingData.csv')\n",
    "test = pd.read_csv('TestData.csv')\n",
    "sample = pd.read_csv('SubmissionFormat.csv')\n",
    "\n",
    "training_data = train[['FTE','Facility_or_Department', 'Function_Description','Fund_Description',\n",
    "                       'Job_Title_Description', 'Location_Description','Object_Description',\n",
    "                       'Position_Extra', 'Program_Description', 'SubFund_Description',\n",
    "                       'Sub_Object_Description', 'Text_1', 'Text_2','Text_3','Text_4', 'Total']]\n",
    "\n",
    "cols = ['Function','Object_Type','Operating_Status','Position_Type','Pre_K', 'Reporting',\n",
    "                'Sharing','Student_Type', 'Use']\n",
    "\n",
    "labels = train[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derri\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "it=['Facility_or_Department', 'Function_Description','Fund_Description',\n",
    "                       'Job_Title_Description', 'Location_Description','Object_Description',\n",
    "                       'Position_Extra', 'Program_Description', 'SubFund_Description',\n",
    "                       'Sub_Object_Description', 'Text_1', 'Text_2','Text_3','Text_4']\n",
    "test_data = test[['FTE','Facility_or_Department', 'Function_Description','Fund_Description',\n",
    "                       'Job_Title_Description', 'Location_Description','Object_Description',\n",
    "                       'Position_Extra', 'Program_Description', 'SubFund_Description',\n",
    "                       'Sub_Object_Description', 'Text_1', 'Text_2','Text_3','Text_4', 'Total']]\n",
    "\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "for i in cols:\n",
    "    labels[i] = label_encoder.fit_transform(np.array(labels[i]))\n",
    "    \n",
    "    \n",
    "training_data = training_data.drop('FTE', axis = 1)\n",
    "training_data = training_data.drop('Total', axis = 1)\n",
    "\n",
    "test_data = test_data.drop('FTE', axis = 1)\n",
    "test_data = test_data.drop('Total', axis = 1)\n",
    "#mans.csv created\n",
    "for i in it:\n",
    "        training_data[i] = training_data[i].apply(clean)\n",
    "for i in it:\n",
    "        test_data[i] = test_data[i].apply(clean)\n",
    "        \n",
    "cleaned=training_data\n",
    "cleaned.to_csv('cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         34\n",
       "1         18\n",
       "2         34\n",
       "3         33\n",
       "4         33\n",
       "5          8\n",
       "6         14\n",
       "7         11\n",
       "8         34\n",
       "9         33\n",
       "10        18\n",
       "11        14\n",
       "12        34\n",
       "13        18\n",
       "14        18\n",
       "15        33\n",
       "16        14\n",
       "17        28\n",
       "18        36\n",
       "19        18\n",
       "20        18\n",
       "21        33\n",
       "22        34\n",
       "23        18\n",
       "24        33\n",
       "25        34\n",
       "26        18\n",
       "27        33\n",
       "28        34\n",
       "29        32\n",
       "          ..\n",
       "400247    30\n",
       "400248    18\n",
       "400249    33\n",
       "400250    34\n",
       "400251    34\n",
       "400252    33\n",
       "400253     0\n",
       "400254    34\n",
       "400255     0\n",
       "400256    34\n",
       "400257    23\n",
       "400258    18\n",
       "400259    18\n",
       "400260    33\n",
       "400261    26\n",
       "400262    34\n",
       "400263    34\n",
       "400264    18\n",
       "400265    32\n",
       "400266    14\n",
       "400267    18\n",
       "400268    33\n",
       "400269    11\n",
       "400270    18\n",
       "400271    34\n",
       "400272    23\n",
       "400273    33\n",
       "400274    21\n",
       "400275    17\n",
       "400276    33\n",
       "Name: Function, Length: 400277, dtype: int32"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['Function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"combined\"] = [' '.join(row) for row in training_data[training_data.columns].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"combined\"] = [' '.join(row) for row in test_data[test_data.columns].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "                  decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "                  encoding='utf-8', input='content', lowercase=True,\n",
       "                  n_features=1048576, ngram_range=(1, 1), norm='l2',\n",
       "                  preprocessor=None, stop_words=None, strip_accents=None,\n",
       "                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf = txt.TfidfVectorizer(ngram_range=(1, 2), max_df=1.0, min_df=10)\n",
    "hsv = txt.HashingVectorizer()\n",
    "\n",
    "\n",
    "tfidf.fit(training_data['combined'])\n",
    "hsv.fit(test_data['combined'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         no_text no_text general fund teacher elementar...\n",
       "1         no_text rgn gob no_text blank no_text contract...\n",
       "2         no_text no_text general purpose school tcher 2...\n",
       "3         no_text unalloc budgets schools no_text teache...\n",
       "4         no_text non project no_text teacher secondary ...\n",
       "5         no_text non project no_text custodian pt jobs ...\n",
       "6         no_text no_text local fund no_text no_text edu...\n",
       "7         no_text non project no_text sub manager food s...\n",
       "8         no_text ela s teaching spanish only no_text te...\n",
       "9         no_text unalloc budgets schools no_text teache...\n",
       "10        no_text state and federal projects coordinatio...\n",
       "11        no_text instruction general fund no_text no_te...\n",
       "12        position control pools no_text general purpose...\n",
       "13        no_text disadvantaged youth title i disadvanta...\n",
       "14        no_text basic fefp k 12 conversion charter sch...\n",
       "15        all campus payroll instruction general operati...\n",
       "16        no_text basic fefp k 12 general fund teacher t...\n",
       "17        no_text security services general admin lieute...\n",
       "18        no_text non project no_text blank no_text elec...\n",
       "19        no_text instruction and curriculum development...\n",
       "20        no_text direction of support services pupils s...\n",
       "21        no_text unalloc budgets schools no_text teache...\n",
       "22        no_text disadvantaged youth title i disadvanta...\n",
       "23        no_text guidance services conversion charter s...\n",
       "24        no_text no_text general purpose school no_text...\n",
       "25        no_text no_text school federal projects tcher ...\n",
       "26        no_text instruction and curriculum development...\n",
       "27        no_text core matters no_text teacher short ter...\n",
       "28        no_text ela e teaching sheltered eng no_text t...\n",
       "29        transportation department transportation gener...\n",
       "                                ...                        \n",
       "400247    no_text psychological services general psychol...\n",
       "400248    new construction department administration fac...\n",
       "400249    no_text unalloc budgets schools no_text teache...\n",
       "400250    no_text special ed severe needs no_text teache...\n",
       "400251    no_text ela s teaching spanish only no_text te...\n",
       "400252    teacher supply no_text school federal projects...\n",
       "400253    no_text title iii ela no_text ela general assi...\n",
       "400254    no_text read to achieve round three no_text te...\n",
       "400255    no_text title i no_text ela general assignment...\n",
       "400256    no_text non project no_text teacher elementary...\n",
       "400257    vocational curriculum development and instruct...\n",
       "400258    no_text basic fefp k 12 conversion charter sch...\n",
       "400259    no_text staff services extended learning cente...\n",
       "400260    no_text no_text school federal projects no_tex...\n",
       "400261    no_text no_text general purpose school assista...\n",
       "400262    no_text title ii part a teacher qualit no_text...\n",
       "400263    no_text ela e teaching sheltered eng no_text t...\n",
       "400264    no_text instruction and curriculum development...\n",
       "400265    transportation department transportation gener...\n",
       "400266    no_text instruction general fund no_text no_te...\n",
       "400267    no_text ns gob no_text secondary spec ed para ...\n",
       "400268    no_text no_text general purpose school no_text...\n",
       "400269    child nutrition food services child nutrition ...\n",
       "400270    no_text other improvements of instruction serv...\n",
       "400271    no_text title ii part a teacher qualit no_text...\n",
       "400272    no_text inst staff training svcs general fund ...\n",
       "400273    no_text title ii d no_text teacher retrd shrt ...\n",
       "400274    no_text no_text schoolwide schools school liai...\n",
       "400275    no_text non project no_text library technician...\n",
       "400276    instruction and curriculum instruction title p...\n",
       "Name: combined, Length: 400277, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'ttfidfransform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-97d09c7606de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mttfidfransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_hsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'ttfidfransform'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X_tfidf = tfidf.ttfidfransform(training_data['combined'])\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_data['combined'])\n",
    "\n",
    "X_hsv = hsv.transform(training_data['combined'])\n",
    "X_test_hsv = hsv.transform(test_data['combined'])\n",
    "\n",
    "X = sparse.hstack((X_hsv, X_tfidf))\n",
    "X_test = sparse.hstack((X_test_hsv, X_test_tfidf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  0\n",
      "label =  1\n",
      "50064 50064\n",
      "label =  2\n",
      "50064 50064\n",
      "label =  3\n",
      "50064 50064\n",
      "label =  4\n",
      "50064 50064\n",
      "label =  5\n",
      "50064 50064\n",
      "label =  6\n",
      "50064 50064\n",
      "label =  7\n",
      "50064 50064\n",
      "label =  8\n",
      "50064 50064\n"
     ]
    }
   ],
   "source": [
    "preds1 = []\n",
    "preds2 = []\n",
    "preds3 = []\n",
    "preds4 = []\n",
    "for i in range(len(cols)):\n",
    "    print (\"label = \", i)\n",
    "    sgd1 = linear_model.SGDClassifier(loss = 'log', max_iter = 120, alpha = 0.000001)\n",
    "    sgd2 = linear_model.SGDClassifier(loss = 'log', max_iter = 120, penalty = 'l1')\n",
    "    sgd3 = linear_model.SGDClassifier(loss = 'log', max_iter = 120, penalty = 'l2')\n",
    "    sgd4 = linear_model.SGDClassifier(loss = 'log', max_iter = 120, penalty = 'elasticnet')\n",
    "    sgd1.fit(X, labels.iloc[:,i])\n",
    "    sgd2.fit(X, labels.iloc[:,i])\n",
    "    sgd3.fit(X, labels.iloc[:,i])\n",
    "    sgd4.fit(X, labels.iloc[:,i])\n",
    "    if i == 0:\n",
    "        preds1 = sgd1.predict_proba(X_test)\n",
    "        preds2 = sgd2.predict_proba(X_test)\n",
    "        preds3 = sgd3.predict_proba(X_test)\n",
    "        preds4 = sgd4.predict_proba(X_test)\n",
    "    else:\n",
    "        print(len(preds1),len(sgd1.predict_proba(X_test)))\n",
    "        preds1 = np.hstack((preds1,sgd1.predict_proba(X_test)))\n",
    "        preds2 = np.hstack((preds2,sgd2.predict_proba(X_test)))\n",
    "        preds3 = np.hstack((preds3,sgd3.predict_proba(X_test)))\n",
    "        preds4 = np.hstack((preds4,sgd4.predict_proba(X_test)))\n",
    "preds = (preds1 + preds2 + preds3 + preds4)/4.0\n",
    "\n",
    "for i in range(1, len(sample.columns)):\n",
    "    colname = sample.columns[i]\n",
    "    sample[str(colname)] = preds[:,i-1]\n",
    "\n",
    "sample.to_csv('Logg_Model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
